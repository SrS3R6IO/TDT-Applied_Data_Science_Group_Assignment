{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis on the students attenton\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9193d81cfe62fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First of all, the necessary imports\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab4b9aac351ff90c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then reading the 80 csv files, getting the time etiquete, which is not set, join all the csv files and sort them by time. Important to mention that this is NOT part of the model. Only for data analysis and estimations before the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "323ebd44a403b503"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the debugging-performance file apart so that we can add a column to the actual data with the score \n",
    "debugging = pd.read_csv(\"applied-data-science-dataset/debugging-performance.csv\")\n",
    "# Make our way easier to handle which participant have which performance\n",
    "performance_dict = dict(zip(debugging['participant'], debugging['performance']))\n",
    "\n",
    "# List to store the individual dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Keep in mind that the debugging performance file is not taken into account \n",
    "for i in range(1, 81):\n",
    "    if i < 10:\n",
    "        file = f\"applied-data-science-dataset/P0{i}.csv\"\n",
    "    else:\n",
    "        file = f\"applied-data-science-dataset/P{i}.csv\"\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df.rename(columns={'Unnamed: 0': 'Time'}, inplace=True)\n",
    "    \n",
    "    name = f'P{i:02}'\n",
    "    df['Source'] = name\n",
    "    df['Performance'] = performance_dict[name]\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Now that all dataframes are loaded and sorted by 'Time', concatenate them\n",
    "# This time, concatenate across columns for each 'Time' value\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.sort_values(by=['Time', 'Source'], inplace=True)\n",
    "\n",
    "combined_df.drop(columns=['Source'], inplace=True)\n",
    "\n",
    "# Reset index after sorting to maintain continuous indexing\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the final combined dataframe to a CSV file\n",
    "combined_df.to_csv(\"combined_dataset.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a269cd0778e4bb35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can focus on preprocessing data: Since the column of \"Time\" isn't set propertly, we can fix that manually, then, pick our training and testing data (only once) by random, the distribution would be 60-20 since is the closest to 2/3 - 1/3 that could work for our model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e0f8fe73f309ecb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DO NOT EXECUTE THIS CODE, THIS ALREADY RANDOMLY GENERATED THE TRAIN AND TEST DATA\n",
    "(In fact I'm going to comment it so that all the cells can be executed) Remove the comment if needed other training data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8c9d7107a9df0f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# This line could be not necessary, but this way, cells can be executed independently\n",
    "file_paths = glob.glob(\"applied-data-science-dataset/P*.csv\")\n",
    "# Read the debugging-performance file apart so that we can add a column to the actual data with the score \n",
    "debugging = pd.read_csv(\"applied-data-science-dataset/debugging-performance.csv\")\n",
    "# Make our way easier to handle which participant have which performance\n",
    "performance_dict = dict(zip(debugging['participant'], debugging['performance']))\n",
    "\n",
    "# Pick randomly 60 students\n",
    "training_files = random.sample(file_paths, 60)\n",
    "\n",
    "testing_files = list(set(file_paths) - set(training_files))\n",
    "\n",
    "training_files.sort()\n",
    "testing_files.sort()\n",
    "\n",
    "\n",
    "# Function to load, rename the time column, and return the DataFrame\n",
    "def load_and_prepare_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df.rename(columns={'Unnamed: 0': 'Time'}, inplace=True) \n",
    "    name = f'P{int(file[30:32]):02}'\n",
    "    df['Source'] = name\n",
    "    df['debuggingPerformance'] = performance_dict[name]\n",
    "    return df\n",
    "\n",
    "# Concatenate the training CSVs\n",
    "training_dfs = [load_and_prepare_csv(file) for file in training_files]\n",
    "training_df = pd.concat(training_dfs, ignore_index=True)\n",
    "\n",
    "# Concatenate the testing CSVs\n",
    "testing_dfs = [load_and_prepare_csv(file) for file in testing_files]\n",
    "testing_df = pd.concat(testing_dfs, ignore_index=True)\n",
    "\n",
    "# Sort both datasets by 'Time' and by the students name (added that column so it's easier to identify them)\n",
    "training_df.sort_values(by=['Time', 'Source'], inplace=True)\n",
    "testing_df.sort_values(by=['Time', 'Source'], inplace=True)\n",
    "\n",
    "training_df.to_csv(\"model_data/training_dataset.csv\", index=False)\n",
    "testing_df.to_csv(\"model_data/testing_dataset.csv\", index=False)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b149850c215e3fd5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the training data and testing data are separated, we can make the rest of the pre-processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb6d47a803ff110"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"model_data/training_dataset.csv\")\n",
    "test_data = pd.read_csv(\"model_data/testing_dataset.csv\")\n",
    "\n",
    "# Now, the point of preprocessing, would be to fill the missing values, in our case with the mean\n",
    "def fill_missing_values(data):\n",
    "    return data.fillna(data.mean())\n",
    "# But since none of the datasets have missing values, theres hardly a point in doing this:\n",
    "training_data = fill_missing_values(training_data)\n",
    "test_data = fill_missing_values(test_data)\n",
    "\n",
    "# The same could be said about scalating the values, but other than the actual time\n",
    "# (which we dont want to scalate) the values are already scalated.\n",
    "\n",
    "def scalate_data(data, columns_to_scale, scaler):\n",
    "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    return df\n",
    "\n",
    "# And finally, depending on which metric we are going to choose for training \n",
    "# (which for example, can be the debugging performance) and split the data accordingly\n",
    "\n",
    "X_train, y_train = training_data.drop(column=['debuggingPerformance']), training_data['debuggingPerformance']\n",
    " \n",
    "X_test, y_test  = test_data.drop(column=['debuggingPerformance']), test_data['debuggingPerformance']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ef18db949a23f57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
